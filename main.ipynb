{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import etree\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='text-align:center'> Scarping With Beautiful Soup</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "execution_count": 16,

   "metadata": {},
   "outputs": [],
   "source": [
    "def soup_func(url):\n",
    "    header = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36 Edg/123.0.0.0'}\n",
    "    r = requests.get(url, headers=header)\n",
    "    return BeautifulSoup(r.text, 'lxml')\n",
    "def pretiffy(soup):\n",
    "    return soup.prettify()\n",
    "def xpath(soup, path):\n",
    "    return etree.HTML(str(soup)).xpath(path)[0].text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mouhamed/projets/biblio/openlib_scarping_with_python/.venv/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openlibrary.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 3,
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get('https://openlibrary.org/trending/forever', verify=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/trending/forever?page=1', '/trending/forever?page=2', '/trending/forever?page=3', '/trending/forever?page=4', '/trending/forever?page=5', '/trending/forever?page=6', '/trending/forever?page=7', '/trending/forever?page=8', '/trending/forever?page=9', '/trending/forever?page=10']\n"
     ]
    }
   ],
   "source": [
    "URL = 'https://openlibrary.org/trending/forever'\n",
    "\n",
    "soup = soup_func(URL)\n",
    "\n",
    "# pagination list pages\n",
    "pagination_links = [link['href'] for link in soup.find_all('a', attrs={'class': 'ChoosePage'})][:-1:]\n",
    "pagination_links = ['/trending/forever?page=1'] + pagination_links\n",
    "print(pagination_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "execution_count": 19,

   "metadata": {},
   "outputs": [],
   "source": [
    "def jump_data(path:str, data:list):\n",
    "    import json\n",
    "    with open(path, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scrape(pagination_links):\n",
    "    for pagination_link in pagination_links:\n",
    "        \n",
    "        # insert into a dictionary format books detail\n",
    "        data = []\n",
    "\n",
    "        URL = f\"https://openlibrary.org{pagination_link}\"\n",
    "\n",
    "        #scarpe the actual pagination link page\n",
    "        pagination_soup = soup_func(URL)\n",
    "\n",
    "        # get the list of books of this actual page\n",
    "        list_group = pagination_soup.find_all('li', attrs={'class': 'searchResultItem'})\n",
    "\n",
    "        # get the link detail page of every book\n",
    "        links_detail_book_page = [link.find('a', attrs={'itemprop': 'url'})['href'] for link in list_group]\n",
    "        for books_detail in links_detail_book_page:\n",
    "            NEW_URL = f\"https://openlibrary.org{books_detail}\"\n",
    "            #book_detail = requests.get(NEW_URL)\n",
    "            new_soup = soup_func(NEW_URL) #BeautifulSoup(book_detail.text, 'html.parser')\n",
    "            publishers = [publisher.text for publisher in new_soup.find_all('a', attrs={'itemprop': 'publisher'})]\n",
    "            try:\n",
    "                isbn = [isbn.text for isbn in new_soup.find_all('dd', attrs={'class': 'object', 'itemprop': 'isbn'})]\n",
    "                isbn10 = isbn[0]\n",
    "                isbn15 = isbn[1]\n",
    "            except:\n",
    "                isbn10 = None\n",
    "                isbn15 = None\n",
    "            try:\n",
    "                page = new_soup.find('span', attrs={'class':'edition-pages' ,'itemprop': 'numberOfPages'}).text\n",
    "            except:\n",
    "                page = None\n",
    "            try:\n",
    "                language = [language.a.text for language in new_soup.find_all('span', attrs={'itemprop':'inLanguage'})]\n",
    "            except ValueError:\n",
    "                language = None\n",
    "            try:\n",
    "                title = new_soup.find('h1', attrs={'class':'work-title', 'itemprop':'name'}).text\n",
    "            except:\n",
    "                title = None\n",
    "            book_data = {\n",
    "                    'title': title,\n",
    "                    'author': new_soup.find('a', attrs={'itemprop': 'author'}).text, #xpath(new_soup, '//*[@id=\"contentBody\"]/div[1]/div[3]/div[2]/span/h2[2]/a'),\n",
    "                    'publication_date': xpath(new_soup, '//*[@id=\"contentBody\"]/div[1]/div[3]/div[5]/div/div[1]/span'),\n",
    "                    'page': page,\n",
    "                    'language': ' '.join(language),\n",
    "                    'publishers': f\"{', '.join(publishers)}\",\n",
    "                    'description': xpath(new_soup, '//*[@id=\"contentBody\"]/div[1]/div[3]/div[4]/div/p[1]'),\n",
    "                    'isbn10': isbn10, #xpath(new_soup, '//*[@id=\"contentBody\"]/div[1]/div[3]/div[9]/div[4]/dl/dd[4]'),\n",
    "                    'isbn15': isbn15,\n",
    "                    'image':new_soup.find('img', attrs={'itemprop': 'image'})['src'],\n",
    "                    'genre':[a.text for a in new_soup.find_all('a', attrs={'data-ol-link-track' : \"BookOverview|SubjectClick\"})]\n",
    "                    }\n",
    "            # print(book_data)    \n",
    "            data.append(book_data)\n",
    "       \n",
    "    return jump_data('data/books.json', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape(pagination_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='text-align:center'> Scarping With Selenium</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.EdgeOptions()\n",
    "service = Service(executable_path='webdriver/edgedriver_win64/msedgedriver.exe')\n",
    "driver = webdriver.Edge(service=service, options=options)\n",
    "driver.get('https://openlibrary.org/')\n",
    "\n",
    "wait = WebDriverWait(driver, 50)\n",
    "# explorer_menu = wait.until(EC.element_to_be_clickable((By.XPATH, '//summary[contains(text(), \"Explorer\")]')))\n",
    "driver.find_element(By.XPATH, '//summary[contains(text(), \"Explorer\")]').click()\n",
    "# Cliquez sur le menu \"Explorer\" pour ouvrir le menu d√©roulant\n",
    "# explorer_menu.click()\n",
    "\n",
    "# driver.quit()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
